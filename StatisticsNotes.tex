\documentclass{book}

\usepackage{setspace}
\usepackage{listings}
\usepackage{appendix}
\usepackage{float}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage[american]{babel}
\usepackage{pythontex}
\usepackage{graphicx}
\usepackage[hyperref=true, backref=true, backend=bibtex8]{biblatex}
\usepackage{csquotes}
\usepackage[pdftex, pdfusetitle, colorlinks, 
		urlcolor=blue, 
		filecolor=blue, 
		linkcolor=blue,
		citecolor=blue,]{hyperref}
\usepackage{datetime}
\settimeformat{ampmtime}

\bibliography{../textbook}

\title{\textsc{Class Notes\\ for \\ Statistics\\ Letu Math--3403}}
\author{Nicholas Capo\\ \href{mailto:nicholas.capo@gmail.com}{nicholas.capo@gmail.com}}

\date{\today\\ \currenttime}

\bibliography{textbook}

\newcommand{\note}[1]{\marginpar{\emph{Note: #1}}}

%%%%%%%%%%%%%%%
\begin{document}
\maketitle

\section*{}
\begin{center}
This document comprises classroom notes from Statistics Class\\ at \href{letu.edu}{LeTourneau University}, in the Fall of 2012.

\vspace{10pt}

Although the author will attempt to be complete and correct in these notes, it is the reader's responsibility to learn and understand the material. The author assumes no responsibility for the completeness or accuracy of this content. 

\vspace{10pt}

If you have any suggestions  or corrections feel free to email the author at \href{mailto:nicholas.capo@gmail.com}{nicholas.capo@gmail.com}

\vspace{10pt}

The latest version of this document is available at:\\ \url{https://bitbucket.org/nicholascapo/statisticsnotes/src/tip/StatisticsNotes.pdf}
\end{center}

\vfill
\begin{tabular}{c}
Copyright \copyright\ 2012 Nicholas Capo\\
Licensed under a {Creative Commons Attribution-ShareAlike 3.0 Unported}\\
\url{http://creativecommons.org/licenses/by-sa/3.0/}\\
\end{tabular}

%%%%%%%%%%%
\tableofcontents
%%%%%%%%%%%

\chapter{Introduction}
\begin{center}
\textbf{Definition of Statistics}\\
\enquote{Statistics is the science of collecting, organizing, analyzing, and interpreting data in order to make decisions.}
\end{center}

\section{Data}

\subsection{Data Sets}
\begin{description}
\item[Population] The collection of all outcomes, responses, measurements, or counts, that are of interest.

\item[Sample] A subset of the population.

\item[Parameter] A number that describes a population characteristic.

\item[Statistic] A number that describes a sample characteristic.
\end{description}

\subsection{Types of Data}

\begin{description}
\item[Qualitative Data] Attributes, labels, or non-numerical entries.

\item[Quantitative Data] Numerical measurements or counts.
\end{description}

\section{Sample Mean and Median}

\subsection{Definition}
\begin{description}
\item[Sample Mean] The average of the sample data points, however it may not be a data point.
$$\overline{x} = \sum_{i=1}^n\frac{x_i}{n} = \frac{x_1+x_2+x_3\cdots x_n}{n}$$
\item[Sample Median] The middle value of the data.

$$\tilde{x}=\left\{
\begin{matrix}
x_{(\frac{n+1}{2})} & \text{if $n$ is odd}\\
\frac{1}{2}(x_{\frac{n}{2}}+x_{\frac{n}{2}+1}) & \text{if $n$ is even}
\end{matrix}
\right.$$

\item[Trimmed Mean] A trimmed mean is computed by trimming off the largest and smallest set of values. For example a 10\% trimmed mean is found by eliminating the largest 10\% and smallest 10\% and computing the mean of the remaining values. This may be useful for data that contains possible outliers. Denoted by $x_{tr(\text{percent})}$
\end{description}

\section{Measures of Variability}

\subsection{Standard Deviation}

\subsubsection{Sample Variance}

$$s^2 = \sum_{i=1}^n \frac{(x_i - \overline{x})^2}{n-1}$$

\subsubsection{Sample Standard Deviation}

$$s=+\sqrt{s^2}$$

The standard deviation is $0$ when all the data points are the same.

\section{Descriptive Statistics}

\subsection{Quartiles}

Quartiles approximately divide an ordered data set into four equal parts.

\begin{description}
\item[First Quartile, $Q_1$]
About $25\%$ of the data fall on or below $Q_1$
\item[Second Quartile, $Q_2$]
About $50\%$ of the data fall on or below $Q_2$
\item[Third Quartile, $Q_3$]
About $75\%$ of the data fall on or below $Q_3$
\end{description}

\subsection{Range and Interquartile Range}

\subsubsection{Range}

$$\text{range} = \text{max value} - \text{min value}$$

\subsubsection{Interquartile Range}

$$IQR=Q_3 - Q_1$$

To help find outliers, compute $1.5 \times IQR$, and any values that lie outside the interval $[Q_1-1.5 \times IQR, Q_3+1.5 \times IQR]$ is a possible (and probable) outlier.

\subsection{Box and Whisker Plot}

Exploratory Data Analysis Tool

\begin{itemize}
\item Requires
	\begin{itemize}
	\item Min
	\item $Q_1$
	\item Median
	\item $Q_3$
	\item Max
	\end{itemize}
\end{itemize}

\begin{pycode}
import pylab
data = [1, 2, 3, 4, 5, 6, 11]
pylab.figure(figsize=(5,2))
pylab.boxplot(data, vert=0, sym='bx')
pylab.savefig('whiskerplot.pdf', bbox_inches='tight', orientation='landscape')
sdata = sorted(data)
min = sdata[0]
outlier = sdata[-1]
max = sdata[-2]
median = pylab.median(sdata)

\end{pycode}

\subsubsection{Example}

\begin{tabular}{ll}
Example Data &\py{data}\\
Min &\py{min}\\
Median & \py{median}\\
Max & \py{max}\\
Outlier & \py{outlier}\\
\end{tabular}


\begin{figure}[H]
\begin{center}
\includegraphics[width=.75\textwidth]{whiskerplot}
\end{center}
\caption{Example Box And Whisker Plot}
\end{figure}

\section{Stem and Leaf Plots}

These look like a sideways histogram

Data: \py{[31, 21, 32, 33, 41, 42, 58, 25, 21]}\\

\begin{tabular}{r|ll}
Stem & Leaf & Key: $a|b=ab$\\
\hline
2&1,1,5\\
3&1,2,3\\
4&1,2\\
5&8\\
\end{tabular}

\subsection{Key Notation}

Key: 4|5 = 45
Key: 4|5 = 4.5

\subsection{Double Stem and Leaf}

Separate the leaves into two groups, (0-4, and 5-9)

Data: \py{[31, 21, 32, 33, 41, 42, 58, 25, 21]}\\

\begin{tabular}{r|ll}
Stem & Leaf & Key: $a|b=ab$\\
\hline
2&1,1\\
2&5\\
3&1,2,3\\
4&1.2\\
4&\\
5&\\
5&8\\
\end{tabular}

\section{Frequency Distribution}
A table that shows classes or intervals of data with a count of the number of entries in each class.

\subsection{Midpoint of a Class}
Average of the class limits.
$$\frac{(\text{lower class limit})+(\text{upper class limit})}{2}$$

\subsection{Relative Frequency}
$$\frac{\text{class frequency}}{\text{sample size}}=\frac{f}{n}$$

\section{Scatter Plots}
Each entry in one data set corresponds to one entry in a second set, one-to-one mapping.

\subsection{Example Scatter Plot}

\begin{pycode}
import pylab
import random
count = 12
data = []
for i in range(count): data.append(random.randint(1, count))
x = range(1, count+1)

pylab.figure(figsize=(5, 5))

pylab.scatter(x, data, label='$(x, y)$')

pylab.legend()
pylab.savefig('scatter.pdf', orientation='landscape')
\end{pycode}

\begin{tabular}{ll}
Data:&\\
X: & \texttt{\py{x}}\\
Y: & \texttt{\py{data}}\\
\end{tabular}

\begin{figure}[H]
\begin{center}
\includegraphics[width=.75\textwidth]{scatter}
\end{center}
\caption{Example Scatter Plot}
\end{figure}

\subsection{Homework}
\begin{itemize}
\item Page 13 \#'s 1.5, 1.6
\item Page 17 \#'s 1.11, 1.12
\item Page 31 \#'s 1.18, 1.19, 1.20, 1.29, 1.30
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Probability}

\section{Experiments}
Any process that generates a set of data.

\section{Sample Space}
The set of all possible outcomes of a statistical experiment, denoted $S$. The sample space with no elements is the empty set or null set, denoted $\emptyset$

\subsection{Example}

$$S = \{ 3, 2, 1, 0\}$$
$$S = \{ x | 0 < x < 25 \}$$
$$S= \{ x^2 | x \in \mathbb{R}\}$$

\subsection{Tree Diagrams}
A Tree Diagram can be used to list all possible outcomes

\subsection{Events}
An event is a subset of a sample space. The null set ($\emptyset$) and the sample space ($S$) are both subsets of the sample space $S$.

\subsubsection{Intersection}
The intersection of two events $A$ and $B$, denoted $A \cap B$, is the event containing all elements that are common to $A$ and $B$. If $A \cap B = \emptyset$ than $A$ and $B$ are called mutually exclusive or disjoint.

\subsubsection{Union}
The union of two events $A$ and $B$, denoted $A \cup B$, is the event containing all elements that belong to $A$ or $B$ or both.

\subsubsection{Compliment}
The compliment of an event $A$ with respect to $S$ is a subset of all elements of $S$ not in $A$, denoted $A'$

\section{Counting Sample Points}

\subsection{Multiplication Rule}
If an operation can be preformed in $n_1$ ways and if for each of the ways a second operation can be preformed in $n_2$ ways, then the two operations can be preformed together in $n_1n_2$ ways. This principle can be extended to more than two operations. See Example 2.14 in \textcite[45]{textbook}

\subsection{Factorial}
For any non-negative integer $n$, $n!$ called \enquote{n factorial}, is defined as $$n!=n(n-1)\cdots(2)(1)$$
with the special case $0!=1$.

\subsection{Permutation}
A permutation is an arrangement of all or a part of a set objects. For permutations the order of objects matters. The number of permutations of $n$ distinct objects is $n!$.

\subsection{Permutations at a Time}
The number of permutations of $n$ distinct objects taken $r$ at a time is
$${}_nP_r = \frac{n!}{(n-r)!}$$
\note{This is called \enquote{$n$ Permute $r$}}

\subsection{Permutations in a Circle}
The number of permutations of $n$ objects arranged in a circle is $(n-1)!$.

\subsection{Permutations of a Kind}
The number of distinct permutations of $n$ objects of which $n_1$ are of one kind, $n_2$ of a second kind, \ldots , $n_k$ of a $k$th kind is

$$\frac{n!}{n_1!n_2! \cdots n_k!}$$

\subsection{Partitioning}
The number of way of partitioning a set of $n$ objects into $k$ cells with $n_1$ elements in the first cell, $n_2$ elements in the second cell, and so forth, is
$$ {n \choose n_1, n_2, \ldots , n_k }= \frac{n!}{n_1!n_2! \cdots n_k!}$$
Where $n_1+n_2+\cdots+n_k = n$

\note{This is the same as the last example}

\subsection{Combinations}

The number of combinations of $n$ distinct object taken $r$ at a time, is:
$${}_nC_r={n \choose r} = \frac{n!}{r!(n-r)!}$$
\note{This is partitioning with only two cells}

\subsection{Partitioning and Combinations}

Note that:

$$ {10 \choose 5, 4, 1} = {10 \choose 5} {5 \choose 4} {1 \choose 1}$$


%%%%%%%%%
\section{Probability of an Event}

The probability of an event $A$ is the sum of the weifhts of all sample points on $A$. Therefore $$0 \le P(A) \le 1$$ $$P(\emptyset)=0$$ $$P(S)=1$$

Furthermore, if $A_1, A_2, \cdots$ is a set of mutually exclusive events, then $$P(A_1 \cup A_2 \cup \cdots)=P(A_1)+P(A_2)+\cdots$$

\subsection{Complimentary Probability}
If $A$ and $A'$ are complimentary events, then $$P(A)+P(A')=1$$

\subsection{Different Outcomes}

If an experiment can result in any one of $N$ different equally likely outcomes, and of exactly $n$ of those outcomes correspond to event $A$, the probability of event $A$ is $$P(A) = \frac{n}{N}$$

\subsection{Additive Rule of Probability}

$$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$

%%%%%%%%%
\subsection{Homework}
\begin{itemize}
\item Page 42 \#'s 2.3, 2.6, 2.10, 2.11, 2.14, 2.16, 2.18
\item Page 51 \#'s 2.24, 2.25, 2.28, 2.29, 2.30, 2.33, 2.34, 2.38, 2.39, 2.40, 2.44, 2.46, 2.47, 2.48
\item Page 59 \#'s 2.52, 2.53, 2.56, 2.57, 2.58, 2.62, 2.67, 2.70
\end{itemize}

\section{Conditional Probability}

The conditional probability of $B$ given $A$, denoted $P(B|A)$ is defined as $$P(B|A) = \frac{P(A \cap B)}{P(A)} \text{, where } P(A) \ne 0 $$
\note{This is a filter}

\subsubsection{Alternate Notation}
$$P(A|B) =\frac{n(A \cap B)}{n(B)}$$
Where $n(x)$ is defined as \enquote{the number of elements in $x$} 

\subsection{Multiplication Rule}
If in an experiment the events $A$ and $B$ can both occur, then $$P(A\cap B) = P(A)P(B|A)\text{, provided } P(A) > 0$$

\subsection{Independent Events}
Two events $A$ and $B$ are \emph{independent} if and only if 
$$P(B|A) = P(B) \text{ or } P(A|B)=P(A)$$
Assuming the existence of the conditional probabilities. Otherwise, $A$ and $B$ are dependent.

\note{Independence does not imply Mutual Exclusivity!}

\subsection{Corollary}
Two events $A$ and $B$ are \emph{independent} if and only if 
$$P(A \cap B) = P(A)P(B)$$

Therefore, to obtain the probability that two independent events will occur, we simply find the product of their individual probabilities.

\subsection{Compliments of Independent Events}
If $A$ and $B$ are independent events so are the complements of these events, this means that: 
\begin{itemize}
\item $A'$ and $B'$ are independent
\item $A'$ and $B$  are independent
\item $A$ and $B'$ are independent
\end{itemize}
\note{Also $P(A'|B) = 1 - P(A|B)$ (no need for independence)}

\subsection{Extended Multiplication for Conditional Probability}
If, in an experiment, the events $A_1, A_2 \cdots A_k$ can occur, then
$$P(A_1 \cap A_2 \cap \cdots \cap A_k) = P(A_1) \times P(A_2|A_1) \times P(A_3|A_1 \cap A_2) \times \cdots \times P(A_k |  A_1 \cap A_2 \cap \cdots \cap A_{k-1})$$

\subsection{Homework}
\begin{itemize}
\item Page 69 \#'s 2.74, 2.75, 2.79, 2.82, 2.84, 2.87, 2.90, 2.92
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Bayes' Rule}

\subsection{Partitioning the Sample Space}
A sample space $A$ can be partitioned into an arbitrary number of subsets. For partitions $B_1, B_2, B_3$ then $$A = (B_1 \cap A) \cup (B_2 \cap A) \cup \cdots \cup (B_3 \cap A)$$

\subsection{Theorem of Total Probability}
$$P(A) = \sum_{i=1}^k P(B_i \cap A) = \sum_{i=1}^k P(B_i)P(A|B_i)$$

\subsection{Bayes Rule}
$$P(B_i|A) 
= \frac{P(B_i \cap A)}{\sum_{i=0}^k P(B_i \cap A)} 
= \frac{P(B_i \cap A)}{\sum_{i=0}^k P(B_i)P(A|B)}$$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Random Variables}

\section{Concept of a Random Variable}

\subsection{Definition}
A random variable, denoted $X$, is a function that associates a real number with each element in the sample space.

\subsection{Discrete Sample Space}
If a sample space contains a finite number of possibilities or an unending sequence with as many elements as there are whole numbers, it is called a \emph{discrete sample space}.

A random variable corresponding with a discrete sample space is called a \emph{discrete random variable}.

\section{Continuous Sample Space}
If a sample space contains an infinite number of possibilities equal to the number of points on a line segment, it is called a \emph{continuous sample space}.

A random variable corresponding with a continuous sample space is called a \emph{continuous random variable}.

\section{Discrete Probability Distribution}
The set of ordered pairs $(x, f(x))$ is a \emph{probability function}, \emph{probability mass function}, or \emph{probability distribution} of the discrete random variable $X$ if, for each possible outcome $x$, 
\begin{enumerate}
\item $f(x) \ge 0$
\item $\sum_x f(x) = 1$
\item $P(X = x) = f(x)$
\end{enumerate}
\note{Probabilities are Functions!} 

\subsection{Cumulative Distribution Function}

The Cumulative Distribution Function $F(x)$ of a discrete random variable$X$ with probability distribution $f(x)$ is
$$F(x)=P(X \le x) = \sum_{t\le x}F(t)\text{, for } -\infty < x < \infty$$

\note{This keeps a running total of the cumulative probabilities up to a value}

\section{Continuous Random Variables}

\subsection{}
The function $f(x)$ is called a probability density function or pdf for the continous random variable $X$, defined over the set of real numbers, if
\begin{enumerate}
\item $$F(x) \ge 0 \text{, for all } x \in R$$
\item $$\int_{-\infty}^{\infty}f(x) \text{dx} = 1$$
\item $$P(a < X < b) = \int_a^b f(x) \text{dx}$$
\end{enumerate}
\note{$P(X=c)=0$, where $a \le c \le b$}

\subsection{Homework}
\begin{itemize}
\item Page 77 \#'s 2.96, 2.97, 2.99, 2.100 Page 91 \#'s 3.1, .32
\item Page 91 \#'s 3.1, 3.2, 3.5, 3.10, 3.11, 3.12, 3.25
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\nocite{textbook}
\printbibliography

\end{document}
